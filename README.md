# EXP-3-PROMPT-ENGINEERING-

## Aim: 
Evaluation of 2024 Prompting Tools Across Diverse AI Platforms: 
ChatGPT, Claude, Bard, Cohere Command, and Meta
Experiment:
Within a specific use case (e.g., summarizing text, answering technical questions), compare the performance, user experience, and response quality of prompting tools across these different AI platforms.

## Algorithm:
Conduct a detailed evaluation of prompting tools and strategies across major AI platforms in 2024, specifically ChatGPT, Claude, Bard, Cohere Command, and Meta. The evaluation should include: (a) an overview of each platform’s prompting capabilities, (b) supported prompting techniques (e.g., zero-shot, few-shot, chain-of-thought, role-based, self-consistency), (c) strengths and weaknesses of each platform in handling different prompting styles, (d) comparative analysis highlighting efficiency, accuracy, creativity, and limitations, and (e) recommendations for best practices in selecting and applying prompting tools across these platforms. Present the results in a structured format with Aim, Methodology, Evaluation Metrics, Comparative Results, and Conclusion.

## Prompt
Conduct a detailed evaluation of prompting tools and strategies across major AI platforms in 2024, specifically ChatGPT, Claude, Bard, Cohere Command, and Meta. The evaluation should include: (a) an overview of each platform’s prompting capabilities, (b) supported prompting techniques (e.g., zero-shot, few-shot, chain-of-thought, role-based, self-consistency), (c) strengths and weaknesses of each platform in handling different prompting styles, (d) comparative analysis highlighting efficiency, accuracy, creativity, and limitations, and (e) recommendations for best practices in selecting and applying prompting tools across these platforms. Present the results in a structured format with Aim, Methodology, Evaluation Metrics, Comparative Results, and Conclusion.

## Output
[exp3prompteng.pdf](https://github.com/user-attachments/files/22125403/exp3prompteng.pdf)

## Result
The experiment will show which AI platform (ChatGPT, Claude, Bard, Cohere Command, Meta) performs best for a chosen use case, and which prompting style (zero-shot, few-shot, CoT, role-based, self-consistency) gives the highest accuracy, clarity, and reliability.

